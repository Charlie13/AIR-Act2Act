# AIR-Act2Act Dataset

- This repository contains scripts to load and view AIR-Act2Act dataset.  
- The AIR-Act2Act is a human-human interaction dataset for training robots nonverbal interaction behaviors. The entire dataset has 5,000 interaction samples of 10 interaction classes: ***bow***, ***handshake***, ***hit***, etc. 
- Each contains depth maps, body indexes and 3D skeletal data captured with three Microsoft Kinect v.2 cameras. 
- In addition, the 3D skeletal data of a human was converted to the NAO robot's joint angles.
  
  
## How to use

0. Run 'viewer.py'
1. Open directory
2. Select data
3. Play videos

![viewer](https://user-images.githubusercontent.com/13827622/58681405-2a105000-83a7-11e9-9946-698b33d31967.png)


## Installation

The scripts are tested on Windows 10 and Python 3.6.1.


## Download

Please follow the link below, and join as a member to get to the download page:
- [http://nanum.etri.re.kr:8080/etriPortal/login?language=en](http://nanum.etri.re.kr:8080/etriPortal/login?language=en)


## Acknowledgement

- This work was supported by the ICT R&D program of MSIP/IITP. [2017-0-00162, Development of Human-care Robot Technology for Aging Society]
