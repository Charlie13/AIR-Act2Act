# AIR-Act2Act Dataset

- This repository contains scripts to load and view AIR-Act2Act dataset.  
- The AIR-Act2Act is a human-human interaction dataset for training robots nonverbal interaction behaviors. The entire dataset has 5,000 interaction samples of 10 interaction classes: ***bow***, ***handshake***, ***hit***, etc. 
- Each contains depth maps, body indexes and 3D skeletal data captured with three Microsoft Kinect v.2 cameras. 
- In addition, the 3D skeletal data of a human was converted to the NAO robot's joint angles.
- Some sample data can be downloaded [here](https://drive.google.com/open?id=1zPcIP3Ma81SxN3swvyhJAhezi8l_Xxo-).     
  
  
## How to use

0. Run 'viewer.py'
1. Open directory
2. Select data
3. Play videos

![viewer](https://user-images.githubusercontent.com/13827622/58681405-2a105000-83a7-11e9-9946-698b33d31967.png)


## Installation

The scripts are tested on Windows 10 and Python 3.6.1.
